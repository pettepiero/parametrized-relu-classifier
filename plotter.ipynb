{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.144166421Z",
     "start_time": "2023-12-27T18:03:24.113541703Z"
    }
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from mpl_toolkits import mplot3d\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, accuracy_score, davies_bouldin_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Used to save data into files\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "# Used to measure time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-27T18:03:24.142724016Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_colors = [\n",
    "    \"#a6cee3\",\n",
    "    \"#1f78b4\",\n",
    "    \"#b2df8a\",\n",
    "    \"#33a02c\",\n",
    "    \"#fb9a99\",\n",
    "    \"#e31a1c\",\n",
    "    \"#fdbf6f\",\n",
    "    \"#ff7f00\",\n",
    "    \"#cab2d6\",\n",
    "    \"#6a3d9a\",\n",
    "]\n",
    "sns.set_palette(custom_colors)\n",
    "\n",
    "ATOL = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.191300941Z",
     "start_time": "2023-12-27T18:03:24.145825225Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"./results/\"  # Replace with the actual path to your folder\n",
    "file_pattern = \"alphas_df*.csv\"\n",
    "\n",
    "# Use glob to match files based on the pattern\n",
    "data_files = glob.glob(f\"{folder_path}/{file_pattern}\")\n",
    "data_files.sort()\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-27T18:03:24.165432768Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_alphas(ax, batch_alpha_0, batch_alpha_1, batch_alpha_2):\n",
    "    xrange = range(len(batch_alpha_0))\n",
    "    ax.plot(xrange, batch_alpha_0, label=\"Alpha 0\")\n",
    "    ax.plot(xrange, batch_alpha_1, label=\"Alpha 1\")\n",
    "    ax.plot(xrange, batch_alpha_2, label=\"Alpha 2\")\n",
    "    # ax.set_xlabel(\"Number of seen batches\")\n",
    "    # ax.set_ylabel(\"Alpha\", rotation=0, labelpad=20)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    # ax.set_title(\n",
    "    #     f\"Alpha0: {round(batch_alpha_0[0].item(), 2)}, Alpha1: {round(batch_alpha_0[1].item(), 2)}, Alpha2: {round(batch_alpha_0[2].item(), 2)}\",\n",
    "    #     fontweight=\"bold\",\n",
    "    # )\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.276738437Z",
     "start_time": "2023-12-27T18:03:24.218633441Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_range = np.arange(start=0, stop=0.051, step=0.005)\n",
    "\n",
    "for f_counter, file in enumerate(data_files):\n",
    "    for counter, lam in enumerate(lambda_range):\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df = df.dropna()\n",
    "\n",
    "        fig, ax = plt.subplots(2, 3, figsize=(12, 8), dpi=200)\n",
    "        ax = ax.flatten()\n",
    "        for i in range(6):\n",
    "            condition = (df[\"lambda\"] == lam) & (df[\"iteration\"] == i)\n",
    "            ax[i] = plot_alphas(\n",
    "                ax[i],\n",
    "                df.loc[condition, \"alpha0\"],\n",
    "                df.loc[condition, \"alpha1\"],\n",
    "                df.loc[condition, \"alpha2\"],\n",
    "            )\n",
    "            ax[i].legend(loc=\"upper center\")\n",
    "        ax[0].set_xlabel(\"Number of seen batches\", fontweight=\"bold\")\n",
    "        ax[0].set_ylabel(r\"$\\alpha$\", rotation=0, labelpad=20, fontweight=\"bold\")\n",
    "        title = r\"$\\alpha$ values for $\\lambda$ = \" + f\"{round(lam, 3)}\"\n",
    "        fig.suptitle(title, size=20, fontweight=\"bold\")\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "        # plt.legend(loc='upper center')\n",
    "        # plt.show()\n",
    "        plt.savefig(f\"./alphas_plots/alphas_{f_counter}_{counter}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-27T18:03:24.262575273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dfs_to_concat = []\n",
    "\n",
    "for i, file in enumerate(data_files):\n",
    "    df = pd.read_csv(file)\n",
    "    lambda_range = df[\"lambda\"].unique()\n",
    "\n",
    "    # Initialize an empty DataFrame for this file\n",
    "    df_for_file = pd.DataFrame(\n",
    "        columns=[\"df\", \"lambda\", \"alpha0\", \"alpha1\", \"alpha2\", \"total\"]\n",
    "    )\n",
    "\n",
    "    # Iterate over unique lambda values\n",
    "    for Lambda in lambda_range:\n",
    "        # Gets the last row for each iteration with the given lambda\n",
    "        df_lambda = df[df[\"lambda\"] == Lambda].groupby(\"iteration\").tail(1)\n",
    "\n",
    "        percentages_lambda = {}\n",
    "        for col in [\"alpha0\", \"alpha1\", \"alpha2\"]:\n",
    "            percentage_zero = np.isclose(df_lambda[col], 0, atol=ATOL).mean() * 100\n",
    "            percentages_lambda[col] = percentage_zero\n",
    "\n",
    "        # Add a row for this lambda to the DataFrame\n",
    "        df_for_lambda = pd.DataFrame(\n",
    "            {\n",
    "                \"df\": [i],\n",
    "                \"lambda\": [Lambda],\n",
    "                \"alpha0\": [percentages_lambda.get(\"alpha0\", np.nan)],\n",
    "                \"alpha1\": [percentages_lambda.get(\"alpha1\", np.nan)],\n",
    "                \"alpha2\": [percentages_lambda.get(\"alpha2\", np.nan)],\n",
    "            }\n",
    "        )\n",
    "        df_for_file = pd.concat([df_for_file, df_for_lambda], ignore_index=True)\n",
    "\n",
    "\n",
    "    # Calculate the total percentage for this file\n",
    "    alphacols = [\"alpha0\", \"alpha1\", \"alpha2\"]\n",
    "    df_for_file[\"total\"] = df_for_file[alphacols].mean(axis=1)\n",
    "\n",
    "    # Add the DataFrame for this file to the list\n",
    "    dfs_to_concat.append(df_for_file)\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into the final result\n",
    "percentages_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "percentages_df = percentages_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-27T18:03:24.288863944Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "for df in percentages_df[\"df\"].unique():\n",
    "    ax.plot(\n",
    "        percentages_df[percentages_df[\"df\"] == df][\"lambda\"],\n",
    "        percentages_df[percentages_df[\"df\"] == df][\"total\"],\n",
    "        marker=\"o\",\n",
    "        label=df,\n",
    "    )\n",
    "ax.set_xlabel(r\"$\\lambda$\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel(\n",
    "    r'% of $\\alpha$' + '\\nthat go to zero',\n",
    "    rotation=0,\n",
    "    labelpad=70,\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax.set_xticks(np.arange(0, 0.051, 0.005))\n",
    "\n",
    "ax.set_yticks(np.arange(0, 101, 10))\n",
    "ax.legend(title=\"Data file\")\n",
    "ax.grid(True, axis=\"y\")\n",
    "plt.savefig(\"./plots/alphas_total.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of converged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.332453821Z",
     "start_time": "2023-12-27T18:03:24.329295643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting all the converged values\n",
    "for file in data_files:\n",
    "    final_values = pd.DataFrame(columns=[\"lambda\", \"alpha0\", \"alpha1\", \"alpha2\"])\n",
    "    df = pd.read_csv(file)\n",
    "    lambda_range = df[\"lambda\"].unique()\n",
    "\n",
    "    for Lambda in lambda_range:\n",
    "        df_lambda = df[df[\"lambda\"] == Lambda].groupby(\"iteration\").tail(1)\n",
    "        final_values = pd.concat(\n",
    "            [final_values, df_lambda[[\"lambda\", \"alpha0\", \"alpha1\", \"alpha2\"]]],\n",
    "            ignore_index=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.345415697Z",
     "start_time": "2023-12-27T18:03:24.341628233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Melt the DataFrame to have a single column for values and another for variable names\n",
    "melted_values = final_values.melt(var_name=\"variable\", value_name=\"value\", id_vars=\"lambda\")\n",
    "print(melted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-27T18:03:24.386540822Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "g = sns.FacetGrid(\n",
    "    melted_values,\n",
    "    row=\"variable\",\n",
    "    hue=\"variable\",\n",
    "    palette=custom_colors,\n",
    "    margin_titles=True\n",
    ")\n",
    "g.map(sns.stripplot, \"value\")\n",
    "g.set(xlim=(0, 1))\n",
    "g.set_titles(\"{value}\", fontweight=\"bold\")\n",
    "\n",
    "g.set_ylabels(\"Count\", rotation=0, labelpad=20, fontweight=\"bold\")\n",
    "g.set_xlabels(r\"$\\alpha$\", fontweight=\"bold\", fontsize=14)\n",
    "g.fig.set_size_inches(10, 5.5)\n",
    "g.fig.set_dpi(200)\n",
    "g.fig.tight_layout()\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 5), dpi=100)\n",
    "# sns.stripplot(data=final_values, x=\"alpha0\", ax=ax, label=\"alpha0\")\n",
    "# sns.stripplot(data=final_values, x=\"alpha1\", ax=ax, label=\"alpha1\")\n",
    "# sns.stripplot(data=final_values, x=\"alpha2\", ax=ax, label=\"alpha2\")\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "sns.scatterplot(\n",
    "    data=melted_values,\n",
    "    x=\"lambda\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    "    palette=custom_colors\n",
    ")\n",
    "ax.set_xlabel(r\"$\\lambda$\", fontweight=\"bold\", fontsize=14)\n",
    "ax.set_ylabel(r\"$\\alpha$\", fontweight=\"bold\", fontsize=14, rotation=0, labelpad=20)\n",
    "\n",
    "fig.savefig(\"./plots/scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-27T18:03:24.387502779Z",
     "start_time": "2023-12-27T18:03:24.386769371Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_edges = [i / 10 for i in range(11)]\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    melted_values,\n",
    "    row=\"variable\",\n",
    "    col=\"lambda\",\n",
    "    hue=\"variable\",\n",
    "    palette=custom_colors,\n",
    "    margin_titles=True\n",
    ")\n",
    "g.map(sns.histplot, \"value\", bins=bin_edges)\n",
    "g.set(xlim=(0, 1))\n",
    "g.set_titles(\"{lambda}\", fontweight=\"bold\")\n",
    "\n",
    "g.set_ylabels(\"Count\", rotation=0, labelpad=20, fontweight=\"bold\")\n",
    "g.set_xlabels(r\"$\\alpha$\", fontweight=\"bold\")\n",
    "g.fig.set_size_inches(15, 5.5)\n",
    "g.fig.set_dpi(200)\n",
    "g.fig.tight_layout()\n",
    "fig.savefig(\"./plots/alpha_hist.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
